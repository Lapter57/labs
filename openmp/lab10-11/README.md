# Лабораторная работа 10-11

## Вариант 2

Реализовать симметричный барьер для n процессов. Эффективность реализации сравнить 
с функцией MPI_Barrier().

### Результат

Для реализации симметричного барьера было решено реализовать барьер с распространением [1].
Согласно предложенному алгоритму каждый процесс синхронизируется с другими за 
$\lceil log_2{n} \rceil$ синхронизируемых раундов, где $n$ - число процессов. Во время раунда $i$ процесс
$p$ отправляет сообщение процессу $2i + p~(mod~n)$.
После отправки сообщения процесс $p$ ждет сообщения от $p - 2i~(mod~n)$ процесса.
Эта симметричный барьер, поэтому схема работает одинаково для всех процессов. 

Для тестирования времени выполнения программы был написан скрипт `stress_test.py`,
который позволяет запустить программу несколько раз на нескольких процессах. В данном случае 
при запуске каждого теста 1000 раз были получены следующие результаты:

**MPI_Barrier()**

| Num proc | Mean time (ms) | Median (ms) | STD (ms) |
| :------: | :------------: | :---------: | :------: |
|    2     |     0.041      |    0.028    |  0.084   |
|    3     |     0.989      |    0.076    |  2.187   |
|    4     |     2.389      |    0.557    |  3.013   |


**disseminationBarrier()**

| Num proc | Mean time (ms) | Median (ms) | STD (ms) |
| :------: | :------------: | :---------: | :------: |
|    2     |     0.036      |    0.029    |  0.026   |
|    3     |     0.819      |    0.079    |  1.967   |
|    4     |     2.182      |    0.508    |  2.910   |


По таблице видно, что с увеличением количества процессов растет время ожидания. 
Также можно заметить что реализация барьера с распространением немного эффективнее
функции *MPI_Barrier*.

[1] Hensgen D., Finkel R., Manber U. Two algorithms for barrier synchronization //International Journal of Parallel Programming. – 1988. – Т. 17. – №. 1. – С. 1-17.
